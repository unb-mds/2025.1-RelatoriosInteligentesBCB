"""
ML Core Interpreter - Prediction Engine
M√≥dulo respons√°vel pelas previs√µes com machine learning

Author: Assistant
Version: 1.1.0
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import warnings
warnings.filterwarnings('ignore')

from .config import PREDICTION_CONFIG, MODEL_CONFIG

class PredictionEngine:
    """
    Classe respons√°vel pelas previs√µes econ√¥micas
    """
    
    def __init__(self):
        self.config = PREDICTION_CONFIG
        self.model_config = MODEL_CONFIG
        self.default_months = self.config['default_months']
        self.max_months = self.config['max_months']
        self.confidence_decay_rate = self.config['confidence_decay_rate']
        self.min_confidence = self.config['min_confidence']
        
    def predict(self, data: pd.DataFrame, months_ahead: int = None, 
                method: str = 'auto') -> Optional[Dict[str, any]]:
        """
        Executa previs√£o usando o m√©todo especificado
        
        Args:
            data: DataFrame com dados hist√≥ricos
            months_ahead: N√∫mero de meses para prever
            method: M√©todo de previs√£o ('auto', 'linear', 'exponential', 'moving_average')
            
        Returns:
            Dict: Resultado da previs√£o ou None se n√£o poss√≠vel
        """
        # Validar par√¢metros
        if months_ahead is None:
            months_ahead = self.default_months
        
        months_ahead = max(1, min(self.max_months, months_ahead))
        
        # Validar dados
        if data.empty or len(data) < 2:
            return self._create_fallback_prediction(data, months_ahead)
        
        # Preparar dados
        clean_data = self._prepare_data(data)
        
        if len(clean_data) < 2:
            return self._create_fallback_prediction(data, months_ahead)
        
        # Escolher m√©todo automaticamente se necess√°rio
        if method == 'auto':
            method = self._select_best_method(clean_data)
        
        # Executar previs√£o baseada no m√©todo
        try:
            if method == 'linear':
                result = self._predict_linear_regression(clean_data, months_ahead)
            elif method == 'exponential':
                result = self._predict_exponential_smoothing(clean_data, months_ahead)
            elif method == 'moving_average':
                result = self._predict_moving_average(clean_data, months_ahead)
            else:
                result = self._predict_linear_regression(clean_data, months_ahead)
            
            if result is None:
                return self._create_fallback_prediction(clean_data, months_ahead)
            
            return result
            
        except Exception as e:
            print(f"Erro na previs√£o: {e}")
            return self._create_fallback_prediction(clean_data, months_ahead)
    
    def _prepare_data(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        Prepara dados para previs√£o
        
        Args:
            data: DataFrame bruto
            
        Returns:
            pd.DataFrame: Dados limpos e ordenados
        """
        # Criar c√≥pia e ordenar
        clean_data = data.copy().sort_values('date').reset_index(drop=True)
        
        # Remover valores nulos e infinitos
        clean_data = clean_data.dropna(subset=['value'])
        clean_data = clean_data[~np.isinf(clean_data['value'])]
        
        # Filtrar outliers extremos (mais de 5 desvios padr√£o)
        if len(clean_data) > 5:
            mean_val = clean_data['value'].mean()
            std_val = clean_data['value'].std()
            if std_val > 0:
                outlier_mask = np.abs(clean_data['value'] - mean_val) < 5 * std_val
                clean_data = clean_data[outlier_mask]
        
        return clean_data
    
    def _select_best_method(self, data: pd.DataFrame) -> str:
        """
        Seleciona automaticamente o melhor m√©todo baseado nos dados
        
        Args:
            data: DataFrame com dados limpos
            
        Returns:
            str: M√©todo recomendado
        """
        n_points = len(data)
        
        # Analisar caracter√≠sticas dos dados
        values = data['value'].values
        volatility = np.std(values) / np.mean(values) if np.mean(values) != 0 else 0
        
        # Analisar tend√™ncia
        x = np.arange(len(values))
        slope, _ = np.polyfit(x, values, 1)
        y_pred = slope * x + np.polyfit(x, values, 1)[1]
        r_squared = 1 - (np.sum((values - y_pred) ** 2) / np.sum((values - np.mean(values)) ** 2))
        
        # L√≥gica de sele√ß√£o
        if n_points < 6:
            return 'moving_average'
        elif n_points < 12:
            return 'exponential' if volatility < 0.2 else 'moving_average'
        else:
            if r_squared > 0.6 and volatility < 0.15:
                return 'linear'
            elif volatility < 0.25:
                return 'exponential'
            else:
                return 'moving_average'
    
    def _predict_linear_regression(self, data: pd.DataFrame, months_ahead: int) -> Optional[Dict[str, any]]:
        """
        Previs√£o usando regress√£o linear
        
        Args:
            data: DataFrame com dados limpos
            months_ahead: N√∫mero de meses para prever
            
        Returns:
            Dict: Resultado da previs√£o ou None
        """
        config = self.model_config['linear_regression']
        
        if len(data) < config['min_data_points']:
            return None
        
        # Preparar vari√°veis
        x = np.arange(len(data))
        y = data['value'].values
        
        # Valida√ß√£o cruzada simples
        split_idx = max(1, int(len(x) * config['validation_split']))
        x_train, x_test = x[:split_idx], x[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]
        
        # Treinar modelo
        slope, intercept = np.polyfit(x_train, y_train, 1)
        
        # Avaliar modelo se h√° dados de teste
        if len(x_test) > 0:
            y_pred_test = slope * x_test + intercept
            rmse = np.sqrt(np.mean((y_test - y_pred_test) ** 2))
        else:
            # Usar dados de treino para estimar erro
            y_pred_train = slope * x_train + intercept
            rmse = np.sqrt(np.mean((y_train - y_pred_train) ** 2))
        
        # Calcular R¬≤
        y_pred_all = slope * x + intercept
        ss_res = np.sum((y - y_pred_all) ** 2)
        ss_tot = np.sum((y - np.mean(y)) ** 2)
        r_squared = 1 - (ss_res / ss_tot) if ss_tot > 1e-10 else 0
        r_squared = max(0, min(1, r_squared))
        
        # Gerar previs√µes futuras
        future_x = np.arange(len(x), len(x) + months_ahead)
        future_values = slope * future_x + intercept
        
        # Gerar datas futuras
        future_dates = self._generate_future_dates(data['date'].max(), months_ahead)
        
        # Calcular intervalos de confian√ßa
        confidence_intervals = self._calculate_confidence_intervals(
            future_values, rmse, months_ahead, 'linear'
        )
        
        # Calcular scores de confian√ßa decrescente
        confidence_scores = self._calculate_confidence_scores(months_ahead, r_squared)
        
        return {
            'dates': future_dates,
            'values': future_values.tolist(),
            'confidence_intervals': confidence_intervals,
            'confidence_scores': confidence_scores,
            'method': 'Regress√£o Linear',
            'rmse': rmse,
            'r_squared': r_squared,
            'model_params': {
                'slope': slope,
                'intercept': intercept,
                'train_size': len(x_train)
            }
        }
    
    def _predict_exponential_smoothing(self, data: pd.DataFrame, months_ahead: int) -> Optional[Dict[str, any]]:
        """
        Previs√£o usando suaviza√ß√£o exponencial (Holt)
        
        Args:
            data: DataFrame com dados limpos
            months_ahead: N√∫mero de meses para prever
            
        Returns:
            Dict: Resultado da previs√£o ou None
        """
        config = self.model_config['exponential_smoothing']
        
        if len(data) < config['min_data_points']:
            return None
        
        values = data['value'].values
        alpha = config['alpha']
        beta = config['beta']
        
        # Inicializa√ß√£o
        level = values[0]
        trend = values[1] - values[0] if len(values) > 1 else 0
        
        # Lista para armazenar previs√µes hist√≥ricas (para calcular erro)
        historical_forecasts = []
        
        # Aplicar suaviza√ß√£o exponencial dupla
        for i in range(1, len(values)):
            # Previs√£o para este ponto
            forecast = level + trend
            historical_forecasts.append(forecast)
            
            # Atualizar componentes
            prev_level = level
            level = alpha * values[i] + (1 - alpha) * (level + trend)
            trend = beta * (level - prev_level) + (1 - beta) * trend
        
        # Calcular erro hist√≥rico
        if len(historical_forecasts) > 0:
            actual_values = values[1:]  # Valores reais correspondentes
            errors = [abs(actual - forecast) for actual, forecast in zip(actual_values, historical_forecasts)]
            rmse = np.sqrt(np.mean([e**2 for e in errors]))
        else:
            rmse = np.std(values) * 0.1
        
        # Gerar previs√µes futuras
        future_values = []
        for i in range(1, months_ahead + 1):
            pred_value = level + trend * i
            future_values.append(pred_value)
        
        # Gerar datas futuras
        future_dates = self._generate_future_dates(data['date'].max(), months_ahead)
        
        # Calcular intervalos de confian√ßa
        confidence_intervals = self._calculate_confidence_intervals(
            future_values, rmse, months_ahead, 'exponential'
        )
        
        # Calcular scores de confian√ßa
        base_confidence = 0.8  # Ligeiramente menor que regress√£o linear
        confidence_scores = self._calculate_confidence_scores(months_ahead, base_confidence)
        
        return {
            'dates': future_dates,
            'values': future_values,
            'confidence_intervals': confidence_intervals,
            'confidence_scores': confidence_scores,
            'method': 'Suaviza√ß√£o Exponencial',
            'rmse': rmse,
            'model_params': {
                'alpha': alpha,
                'beta': beta,
                'final_level': level,
                'final_trend': trend
            }
        }
    
    def _predict_moving_average(self, data: pd.DataFrame, months_ahead: int) -> Optional[Dict[str, any]]:
        """
        Previs√£o usando m√©dia m√≥vel adaptativa
        
        Args:
            data: DataFrame com dados limpos
            months_ahead: N√∫mero de meses para prever
            
        Returns:
            Dict: Resultado da previs√£o ou None
        """
        config = self.model_config['moving_average']
        
        if len(data) < config['min_data_points']:
            return None
        
        values = data['value'].values
        alpha = config['alpha']
        
        # Determinar janela √≥tima
        max_window = min(config['max_window'], len(values))
        optimal_window = min(max(3, len(values) // 4), max_window)
        
        # Pesos exponenciais para m√©dia m√≥vel ponderada
        weights = np.array([alpha * (1 - alpha)**i for i in range(optimal_window)])
        weights = weights / weights.sum()
        
        # Calcular m√©dia m√≥vel ponderada
        recent_values = values[-optimal_window:]
        ma_value = np.average(recent_values, weights=weights)
        
        # Estimar tend√™ncia usando regress√£o nos dados recentes
        recent_window = min(len(values), optimal_window)
        recent_x = np.arange(recent_window)
        recent_y = values[-recent_window:]
        
        if len(recent_y) >= 2:
            trend, _ = np.polyfit(recent_x, recent_y, 1)
        else:
            trend = 0
        
        # Calcular volatilidade para intervalos de confian√ßa
        volatility = np.std(values[-min(12, len(values)):])
        
        # Gerar previs√µes com decay da tend√™ncia
        future_values = []
        current_level = ma_value
        
        for i in range(months_ahead):
            # Aplicar decay na tend√™ncia para evitar extrapola√ß√£o excessiva
            trend_factor = np.exp(-0.1 * i)
            pred_value = current_level + trend * trend_factor
            future_values.append(pred_value)
            
            # Atualizar n√≠vel com suaviza√ß√£o
            current_level = alpha * pred_value + (1 - alpha) * current_level
        
        # Gerar datas futuras
        future_dates = self._generate_future_dates(data['date'].max(), months_ahead)
        
        # Calcular intervalos de confian√ßa baseados na volatilidade
        confidence_intervals = []
        for i, pred in enumerate(future_values):
            margin = volatility * (1 + 0.25 * i) * 1.5
            confidence_intervals.append((pred - margin, pred + margin))
        
        # Calcular scores de confian√ßa
        base_confidence = 0.75  # Menor que outros m√©todos
        confidence_scores = self._calculate_confidence_scores(months_ahead, base_confidence)
        
        return {
            'dates': future_dates,
            'values': future_values,
            'confidence_intervals': confidence_intervals,
            'confidence_scores': confidence_scores,
            'method': 'M√©dia M√≥vel Adaptativa',
            'rmse': volatility,
            'model_params': {
                'window_size': optimal_window,
                'alpha': alpha,
                'trend': trend,
                'ma_value': ma_value
            }
        }
    
    def _generate_future_dates(self, last_date: pd.Timestamp, months_ahead: int) -> List[datetime]:
        """
        Gera lista de datas futuras
        
        Args:
            last_date: √öltima data dos dados hist√≥ricos
            months_ahead: N√∫mero de meses √† frente
            
        Returns:
            List[datetime]: Lista de datas futuras
        """
        future_dates = []
        current_date = last_date
        
        for i in range(months_ahead):
            # Adicionar um m√™s
            if current_date.month == 12:
                next_date = current_date.replace(year=current_date.year + 1, month=1)
            else:
                next_date = current_date.replace(month=current_date.month + 1)
            
            future_dates.append(next_date.to_pydatetime())
            current_date = next_date
        
        return future_dates
    
    def _calculate_confidence_intervals(self, predictions: List[float], rmse: float, 
                                      months_ahead: int, method: str) -> List[Tuple[float, float]]:
        """
        Calcula intervalos de confian√ßa para as previs√µes
        
        Args:
            predictions: Lista de valores previstos
            rmse: Erro quadr√°tico m√©dio do modelo
            months_ahead: N√∫mero de meses previstos
            method: M√©todo de previs√£o usado
            
        Returns:
            List[Tuple[float, float]]: Lista de intervalos (inferior, superior)
        """
        intervals = []
        
        # Fator base baseado no m√©todo
        if method == 'linear':
            base_factor = 1.96  # 95% de confian√ßa
        elif method == 'exponential':
            base_factor = 2.0
        else:
            base_factor = 1.5
        
        for i, pred in enumerate(predictions):
            # Margem cresce com o tempo e inclui incerteza do modelo
            time_factor = 1 + 0.15 * i  # Cresce 15% por m√™s
            margin = rmse * base_factor * time_factor
            
            intervals.append((pred - margin, pred + margin))
        
        return intervals
    
    def _calculate_confidence_scores(self, months_ahead: int, base_confidence: float = 0.9) -> List[float]:
        """
        Calcula scores de confian√ßa decrescente
        
        Args:
            months_ahead: N√∫mero de meses previstos
            base_confidence: Confian√ßa inicial (0-1)
            
        Returns:
            List[float]: Lista de scores de confian√ßa
        """
        scores = []
        
        for i in range(months_ahead):
            # Decay exponencial da confian√ßa
            confidence = base_confidence * np.exp(-self.confidence_decay_rate * i)
            confidence = max(confidence, self.min_confidence)
            scores.append(confidence)
        
        return scores
    
    def _create_fallback_prediction(self, data: pd.DataFrame, months_ahead: int) -> Dict[str, any]:
        """
        Cria previs√£o de fallback para casos de erro ou dados insuficientes
        
        Args:
            data: DataFrame com dados (pode estar vazio)
            months_ahead: N√∫mero de meses para prever
            
        Returns:
            Dict: Previs√£o de fallback
        """
        # Usar √∫ltimo valor dispon√≠vel ou zero
        if not data.empty and 'value' in data.columns:
            last_value = data['value'].iloc[-1]
            last_date = data['date'].max()
        else:
            last_value = 0
            last_date = pd.Timestamp.now()
        
        # Gerar datas futuras
        future_dates = self._generate_future_dates(last_date, months_ahead)
        
        # Previs√µes constantes (√∫ltimo valor)
        future_values = [last_value] * months_ahead
        
        # Intervalos de confian√ßa amplos
        confidence_intervals = [(val * 0.8, val * 1.2) for val in future_values]
        
        # Confian√ßa baixa
        confidence_scores = [0.3] * months_ahead
        
        return {
            'dates': future_dates,
            'values': future_values,
            'confidence_intervals': confidence_intervals,
            'confidence_scores': confidence_scores,
            'method': 'Fallback Simples',
            'rmse': None,
            'model_params': {
                'fallback_reason': 'Dados insuficientes ou erro no modelo',
                'base_value': last_value
            }
        }
    
    def evaluate_prediction_quality(self, data: pd.DataFrame, prediction_result: Dict[str, any]) -> Dict[str, any]:
        """
        Avalia a qualidade da previs√£o baseada nos dados hist√≥ricos
        
        Args:
            data: DataFrame com dados hist√≥ricos
            prediction_result: Resultado da previs√£o
            
        Returns:
            Dict: M√©tricas de qualidade da previs√£o
        """
        if data.empty or not prediction_result:
            return {
                'quality_score': 0,
                'reliability': 'Baixa',
                'factors': []
            }
        
        # Fatores que influenciam a qualidade
        factors = []
        quality_points = 0
        max_points = 0
        
        # 1. Quantidade de dados hist√≥ricos
        n_points = len(data)
        max_points += 20
        if n_points >= 24:
            quality_points += 20
            factors.append("‚úÖ Dados hist√≥ricos suficientes (24+ pontos)")
        elif n_points >= 12:
            quality_points += 15
            factors.append("‚ö†Ô∏è Dados hist√≥ricos moderados (12-23 pontos)")
        else:
            quality_points += 5
            factors.append("‚ùå Poucos dados hist√≥ricos (<12 pontos)")
        
        # 2. Qualidade do modelo (R¬≤ se dispon√≠vel)
        max_points += 25
        r_squared = prediction_result.get('r_squared', 0)
        if r_squared > 0.7:
            quality_points += 25
            factors.append("‚úÖ Modelo com alta precis√£o (R¬≤ > 0.7)")
        elif r_squared > 0.5:
            quality_points += 18
            factors.append("‚ö†Ô∏è Modelo com precis√£o moderada (R¬≤ > 0.5)")
        elif r_squared > 0.3:
            quality_points += 10
            factors.append("‚ö†Ô∏è Modelo com baixa precis√£o (R¬≤ > 0.3)")
        else:
            quality_points += 5
            factors.append("‚ùå Modelo com precis√£o muito baixa (R¬≤ ‚â§ 0.3)")
        
        # 3. Volatilidade dos dados
        max_points += 20
        volatility = np.std(data['value']) / np.mean(data['value']) * 100 if np.mean(data['value']) != 0 else 100
        if volatility < 10:
            quality_points += 20
            factors.append("‚úÖ Baixa volatilidade (<10%)")
        elif volatility < 25:
            quality_points += 15
            factors.append("‚ö†Ô∏è Volatilidade moderada (10-25%)")
        elif volatility < 50:
            quality_points += 8
            factors.append("‚ö†Ô∏è Alta volatilidade (25-50%)")
        else:
            quality_points += 3
            factors.append("‚ùå Volatilidade muito alta (>50%)")
        
        # 4. M√©todo usado
        max_points += 15
        method = prediction_result.get('method', '')
        if 'Linear' in method:
            quality_points += 15
            factors.append("‚úÖ M√©todo robusto (Regress√£o Linear)")
        elif 'Exponential' in method:
            quality_points += 12
            factors.append("‚úÖ M√©todo adaptativo (Suaviza√ß√£o Exponencial)")
        elif 'Moving' in method:
            quality_points += 8
            factors.append("‚ö†Ô∏è M√©todo conservador (M√©dia M√≥vel)")
        else:
            quality_points += 3
            factors.append("‚ùå M√©todo de fallback")
        
        # 5. Consist√™ncia da tend√™ncia
        max_points += 20
        values = data['value'].values
        if len(values) >= 6:
            # Analisar consist√™ncia dividindo dados em duas metades
            mid_point = len(values) // 2
            first_half = values[:mid_point]
            second_half = values[mid_point:]
            
            # Tend√™ncia da primeira metade
            x1 = np.arange(len(first_half))
            slope1 = np.polyfit(x1, first_half, 1)[0] if len(first_half) >= 2 else 0
            
            # Tend√™ncia da segunda metade
            x2 = np.arange(len(second_half))
            slope2 = np.polyfit(x2, second_half, 1)[0] if len(second_half) >= 2 else 0
            
            # Verificar consist√™ncia
            if np.sign(slope1) == np.sign(slope2) and abs(slope1) > 1e-10 and abs(slope2) > 1e-10:
                quality_points += 20
                factors.append("‚úÖ Tend√™ncia consistente ao longo do tempo")
            elif abs(slope1) < 1e-10 and abs(slope2) < 1e-10:
                quality_points += 15
                factors.append("‚úÖ Comportamento est√°vel consistente")
            else:
                quality_points += 8
                factors.append("‚ö†Ô∏è Mudan√ßa de tend√™ncia detectada")
        else:
            quality_points += 10
            factors.append("‚ö†Ô∏è Dados insuficientes para avaliar consist√™ncia")
        
        # Calcular score final
        quality_score = (quality_points / max_points) * 100
        
        # Classificar confiabilidade
        if quality_score >= 80:
            reliability = 'Alta'
        elif quality_score >= 60:
            reliability = 'Moderada'
        elif quality_score >= 40:
            reliability = 'Baixa'
        else:
            reliability = 'Muito Baixa'
        
        return {
            'quality_score': round(quality_score, 1),
            'reliability': reliability,
            'factors': factors,
            'details': {
                'data_points': n_points,
                'model_accuracy': r_squared,
                'volatility': round(volatility, 1),
                'method': method,
                'max_possible_score': max_points,
                'achieved_score': quality_points
            }
        }
    
    def compare_prediction_methods(self, data: pd.DataFrame, months_ahead: int = 6) -> Dict[str, any]:
        """
        Compara diferentes m√©todos de previs√£o no mesmo dataset
        
        Args:
            data: DataFrame com dados hist√≥ricos
            months_ahead: N√∫mero de meses para prever
            
        Returns:
            Dict: Compara√ß√£o entre m√©todos
        """
        methods = ['linear', 'exponential', 'moving_average']
        results = {}
        
        # Executar cada m√©todo
        for method in methods:
            try:
                result = self.predict(data, months_ahead, method)
                if result:
                    quality = self.evaluate_prediction_quality(data, result)
                    results[method] = {
                        'prediction': result,
                        'quality': quality
                    }
            except Exception as e:
                results[method] = {
                    'prediction': None,
                    'quality': {'quality_score': 0, 'reliability': 'Erro'},
                    'error': str(e)
                }
        
        # Encontrar melhor m√©todo
        best_method = None
        best_score = 0
        
        for method, data_method in results.items():
            if data_method['prediction'] and data_method['quality']['quality_score'] > best_score:
                best_score = data_method['quality']['quality_score']
                best_method = method
        
        # Recomenda√ß√£o
        recommendation = self._generate_method_recommendation(results, best_method)
        
        return {
            'results': results,
            'best_method': best_method,
            'best_score': best_score,
            'recommendation': recommendation,
            'summary': self._generate_comparison_summary(results)
        }
    
    def _generate_method_recommendation(self, results: Dict, best_method: str) -> str:
        """Gera recomenda√ß√£o de m√©todo baseada nos resultados"""
        if not best_method:
            return "Dados insuficientes para fazer recomenda√ß√£o confi√°vel. Use dados adicionais."
        
        best_result = results[best_method]
        score = best_result['quality']['quality_score']
        
        method_names = {
            'linear': 'Regress√£o Linear',
            'exponential': 'Suaviza√ß√£o Exponencial',
            'moving_average': 'M√©dia M√≥vel'
        }
        
        recommendation = f"Recomendamos usar {method_names.get(best_method, best_method)} "
        
        if score >= 80:
            recommendation += f"(qualidade alta: {score:.1f}%). Este m√©todo apresenta excelente adequa√ß√£o aos dados."
        elif score >= 60:
            recommendation += f"(qualidade moderada: {score:.1f}%). Este m√©todo √© adequado, mas monitore a precis√£o."
        else:
            recommendation += f"(qualidade baixa: {score:.1f}%). Use com cautela e considere coletar mais dados."
        
        return recommendation
    
    def _generate_comparison_summary(self, results: Dict) -> List[str]:
        """Gera resumo da compara√ß√£o entre m√©todos"""
        summary = []
        
        valid_results = {k: v for k, v in results.items() if v['prediction'] is not None}
        
        if not valid_results:
            return ["Nenhum m√©todo conseguiu gerar previs√µes v√°lidas com os dados fornecidos."]
        
        # Ordenar por qualidade
        sorted_methods = sorted(valid_results.items(), 
                              key=lambda x: x[1]['quality']['quality_score'], 
                              reverse=True)
        
        method_names = {
            'linear': 'Regress√£o Linear',
            'exponential': 'Suaviza√ß√£o Exponencial', 
            'moving_average': 'M√©dia M√≥vel'
        }
        
        # Melhor m√©todo
        best_method, best_data = sorted_methods[0]
        summary.append(f"ü•á {method_names[best_method]}: melhor performance ({best_data['quality']['quality_score']:.1f}%)")
        
        # Outros m√©todos
        for method, data in sorted_methods[1:]:
            score = data['quality']['quality_score']
            if score >= 60:
                summary.append(f"‚úÖ {method_names[method]}: boa alternativa ({score:.1f}%)")
            elif score >= 40:
                summary.append(f"‚ö†Ô∏è {method_names[method]}: adequado com limita√ß√µes ({score:.1f}%)")
            else:
                summary.append(f"‚ùå {method_names[method]}: n√£o recomendado ({score:.1f}%)")
        
        return summary
    
    def get_prediction_explanation(self, prediction_result: Dict[str, any]) -> Dict[str, any]:
        """
        Gera explica√ß√£o detalhada sobre como a previs√£o foi gerada
        
        Args:
            prediction_result: Resultado da previs√£o
            
        Returns:
            Dict: Explica√ß√£o detalhada
        """
        if not prediction_result:
            return {
                'method_explanation': 'N√£o foi poss√≠vel gerar previs√£o',
                'confidence_explanation': 'N/A',
                'limitations': ['Dados insuficientes']
            }
        
        method = prediction_result.get('method', 'Desconhecido')
        
        # Explica√ß√µes por m√©todo
        method_explanations = {
            'Regress√£o Linear': {
                'description': 'Identifica tend√™ncia linear nos dados hist√≥ricos e projeta para o futuro',
                'assumptions': ['Tend√™ncia linear continua', 'Sem mudan√ßas estruturais', 'Padr√£o hist√≥rico se mant√©m'],
                'best_for': 'Dados com tend√™ncia clara e constante',
                'limitations': ['N√£o captura sazonalidade', 'Sens√≠vel a outliers', 'Assume linearidade']
            },
            'Suaviza√ß√£o Exponencial': {
                'description': 'Usa m√©dia ponderada dando mais peso aos dados recentes e captura tend√™ncia',
                'assumptions': ['Dados recentes s√£o mais relevantes', 'Tend√™ncia pode mudar gradualmente'],
                'best_for': 'Dados com tend√™ncia vari√°vel e mudan√ßas graduais',
                'limitations': ['N√£o captura mudan√ßas abruptas', 'Requer calibra√ß√£o de par√¢metros']
            },
            'M√©dia M√≥vel Adaptativa': {
                'description': 'Calcula m√©dia dos valores recentes com pesos decrescentes',
                'assumptions': ['Futuro pr√≥ximo similar ao passado recente', 'Mudan√ßas graduais'],
                'best_for': 'Dados est√°veis ou com alta volatilidade',
                'limitations': ['Reativo a mudan√ßas', 'N√£o prev√™ revers√µes de tend√™ncia']
            }
        }
        
        # Explica√ß√£o da confian√ßa
        avg_confidence = np.mean(prediction_result.get('confidence_scores', [0]))
        
        if avg_confidence > 0.7:
            confidence_explanation = "Alta confian√ßa: dados hist√≥ricos mostram padr√£o claro e consistente"
        elif avg_confidence > 0.5:
            confidence_explanation = "Confian√ßa moderada: alguns padr√µes identificados, mas com incertezas"
        elif avg_confidence > 0.3:
            confidence_explanation = "Baixa confian√ßa: padr√µes pouco claros ou dados vol√°teis"
        else:
            confidence_explanation = "Confian√ßa muito baixa: dados insuficientes ou muito irregulares"
        
        return {
            'method_explanation': method_explanations.get(method, {
                'description': f'M√©todo {method} aplicado aos dados',
                'assumptions': ['Padr√µes hist√≥ricos se mant√™m'],
                'best_for': 'Casos gerais',
                'limitations': ['Baseado apenas em dados hist√≥ricos']
            }),
            'confidence_explanation': confidence_explanation,
            'confidence_decay': 'Confian√ßa diminui exponencialmente com o tempo (15% por m√™s)',
            'interval_explanation': 'Intervalos de confian√ßa mostram faixa prov√°vel de valores reais',
            'general_limitations': [
                'Baseado apenas em dados hist√≥ricos',
                'N√£o prev√™ eventos extraordin√°rios',
                'Assume continuidade de padr√µes',
                'N√£o considera fatores externos',
                'Precis√£o diminui com horizonte temporal'
            ]
        }